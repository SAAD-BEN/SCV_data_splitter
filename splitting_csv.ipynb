{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pyodbc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_exists(cursor, table_name):\n",
    "    cursor.execute(f\"SELECT * FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = '{table_name}'\")\n",
    "    return cursor.fetchone() is not None\n",
    "\n",
    "def create_table(cursor, table_name, columns, column_types):\n",
    "    # strip spaces from column names\n",
    "    columns = [column.strip() for column in columns]\n",
    "    # replace spaces and special characters with underscores\n",
    "    columns = [column.replace(' ', '_') for column in columns]\n",
    "    columns = [column.replace('(', '') for column in columns]\n",
    "    columns = [column.replace(')', '') for column in columns]\n",
    "    columns = [column.replace('/', '_') for column in columns]\n",
    "    columns = [column.replace('-', '_') for column in columns]\n",
    "    columns = [column.replace('%', 'percent') for column in columns]\n",
    "    columns = [column.replace('.', '_') for column in columns]\n",
    "    columns = [column.replace('?', '') for column in columns]\n",
    "    columns = [column.replace('\\'', '') for column in columns]\n",
    "    columns = [column.replace('\\\"', '') for column in columns]\n",
    "    columns = [column.replace(',', '') for column in columns]\n",
    "    columns = [column.replace('&', 'and') for column in columns]\n",
    "    columns = [column.replace('__', '_') for column in columns]\n",
    "    columns = [column.strip() for column in columns]\n",
    "    # create column string for SQL query\n",
    "    column_str = ', '.join([f'{col} {column_types[i]}' for i, col in enumerate(columns)])\n",
    "    create_query = f\"CREATE TABLE {table_name} ({column_str})\"\n",
    "    cursor.execute(create_query)\n",
    "\n",
    "def get_column_types(df):\n",
    "    column_types = []\n",
    "    for col in df.columns:\n",
    "        column_type = df[col].dtype\n",
    "        # Convert pandas types to SQL Server types\n",
    "        if column_type == 'int64':\n",
    "            column_types.append('INT')\n",
    "        elif column_type == 'float64':\n",
    "            column_types.append('FLOAT')\n",
    "        else:\n",
    "            # If the type is object or any other unrecognized type, use NVARCHAR\n",
    "            column_types.append('NVARCHAR(MAX)')\n",
    "    return column_types\n",
    "\n",
    "def split_data(csv_file, json_file, database_name, table_name, json_split=0.3, db_split=0.3, csv_split=0.4):\n",
    "    # Load data from CSV file using pandas\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Shuffle the rows to ensure random data distribution\n",
    "    df = df.sample(frac=1, random_state=42)\n",
    "    \n",
    "    # Calculate the number of rows needed for each destination\n",
    "    total_rows = len(df)\n",
    "    json_rows = int(total_rows * json_split)\n",
    "    db_rows = int(total_rows * db_split)\n",
    "    csv_rows = total_rows - json_rows - db_rows\n",
    "    \n",
    "    # Split the data into JSON, database, and CSV\n",
    "    json_data = df.iloc[:json_rows]\n",
    "    db_data = df.iloc[json_rows:json_rows + db_rows]\n",
    "    csv_data = df.iloc[json_rows + db_rows:]\n",
    "    \n",
    "    # Save the JSON data to a JSON file\n",
    "    json_data.to_json(json_file, orient='records', lines=True)\n",
    "    \n",
    "    # Save the CSV data to a CSV file (without header)\n",
    "    csv_data.to_csv('data/splitted/output.csv', index=False)\n",
    "    \n",
    "    # Get column types for the database table\n",
    "    column_types = get_column_types(df)\n",
    "    \n",
    "    # Save the database data to the specified database and table\n",
    "    connection_string = f'DRIVER=SQL Server;SERVER=LAPTOP-K8C2EPLP\\\\SQLEXPRESS;DATABASE={database_name};Trusted_Connection=yes;'\n",
    "    with pyodbc.connect(connection_string) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            # Create the table if it doesn't exist\n",
    "            if not table_exists(cursor, table_name):\n",
    "                create_table(cursor, table_name, df.columns, column_types)\n",
    "                conn.commit()\n",
    "            # Insert the data into the table\n",
    "            db_data = db_data.where(pd.notna(db_data), None)\n",
    "            # get the values as a list of tuples\n",
    "            values = [tuple(row) for row in db_data.values]\n",
    "            # create the query string with the correct number of placeholders\n",
    "            placeholders = ', '.join(['?'] * len(df.columns))\n",
    "            query = f'INSERT INTO {table_name} VALUES ({placeholders})'\n",
    "            # execute the query\n",
    "            cursor.executemany(query, values)\n",
    "            conn.commit()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "split_data('data/Electric_Vehicle_Population_Size_History_By_County.csv', 'data/splitted/json.json', 'splitted', 'Vehicules', json_split=0.3, db_split=0.3, csv_split=0.4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
